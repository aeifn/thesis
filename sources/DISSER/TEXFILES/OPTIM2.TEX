\section{Модель: основные предположения}

Наша модель~--- это вариант модели \лк Начальник~--- Подчинённый\пк со 
множеством подчинённых (или, что то же самое, игра по Штакельбергу со
множеством игроков второго уровня). Предполагается, что в некоторый момент 
времени подчинённые одновременно выбирают {\em действие} $z \in [0,1]$, 
которое в терминах нашей задачи интерпретируется как частота входа в сговор, 
приводящего ко взятию взятки подчиненным. Обозначим за $q$ профиль выбранных 
частот.

Мы будем предполагать, что у нас имеется континуум подчинённых. Подчинённые 
параметризованы точками $\theta \in [0,1]$ (а профиль $q \in [0,1]^{[0,1]}$). 
Мы назовём $\th$ {\em именем} подчинённого. Выбирая действие $z \in [0,1]$, 
подчинённый $\th$ собирает $z \cdot b(\th)$ денег, где $b(\th)$~--- тип 
подчинённого, отражающий его коррупционные возможности\footnote{Мы могли бы 
назвать $b$ просто размером взятки, предлагаемым в секторе, курируемом 
подчинённым $\th$, но будет удобно вместо этого считать $b(\th)$ максимальной 
суммой денег, которую можно получить в данном секторе, беря взятки во всех 
случаях.}.

Кумулятивная функция распределения $G(\cdot)$ подчинённых по коррупционным
возможностям предполагается общим знанием как контролирующего органа, так и 
всего сообщества подчинённых. Для простоты мы ограничимся дискретными 
распределениями $G(\cdot)$; такое распределение характеризуется набором
\begin{equation}
\label{podklass}
(b_1, \mu_1; \dots; b_n, \mu_n),
\end{equation}
где $(\mu_1, \dots, \mu_n)$ обозначают доли подчинённых, имеющих 
соответствующее $b$ в качестве своих коррупционных возможностей 
($\sum \mu_i = 1$). Предполагается, что $b_i$ неубывает по $i$ 
(не ограничивая общности).

Мы предположим, что выборы $z=q(\th)$ всех подчиненных становятся известными
контролирующему органу. Однако процедура наказания требует верификации, 
выявляющей конкретные случаи коррумпированных действий. Исходя из наблюдаемого
профиля $q$ выбранных подчинёнными действий, контролирующий орган выбирает 
степень тщательности, или интенсивности $\lambda_q (z)$ проверки подчиненных, 
выбравших $z$, при условии реализации профиля $q$. Так как сами по себе 
подчинённые неразличимы (что означает ненаблюдаемость параметра $\th$), 
стратегия верификации может базироваться только на знании переменной выбора, 
или действия подчинённого, $z$, и если различные подчинённые выбирают одно и 
то же $z$, то они должны быть проверяемы с одной и той же частотой 
$\lambda_q (z)$.

Мы предположим, что монетарные издержки подчинённого пропорциональны как его
действию, $z$, так и интенсивности проверки, осуществляемой над ним, 
$\lambda_q (z)$. Например, в истории с налогоукрытием естественно 
интерпретировать $\lambda$ как долю всех актов взаимодействия инспектора с 
фирмами, которые будут проверены. Далее, стоимость одной проверки будем 
считать фиксированной и постоянной. Тогда задача контролирующего органа~--- 
распределить имеющееся в его распоряжении количество проверок между 
подчинёнными, в зависимости от наблюдённого профиля $q$. Предполагая штраф 
$D$ фиксированным и неизменным\footnote{Как правило, он определяется 
существующим законодательством.}, мы видим, что инспектор теряет в среднем
$D \cdot z \cdot \lambda_q (z)$.

Зададим балансовое ограничение контролирующего органа. Для этого потребуем, 
чтобы все $\lambda$ в сумме не превышали $A$. Тонкость состоит в том, что нам 
надо записать это условие в терминах наблюдаемых характеристик, $q$ ({\em не} 
в терминах $\th$, что было бы тривиально). Чтобы сделать это, мы введём 
обозначение $F(\cdot)$ для кумулятивной функции распределения подчинённых 
{\em по параметру их выбора, или действия}; в отличие от $G(\cdot)$, 
это~--- апостериорная характеристика сообщества подчинённых. Она получается 
из профиля $q$ следующим образом:
\begin{equation}
\label{distr17}
\begin{array}{c}
F(z)=F_q(z)= \mbox{ мера Лебега множества } 
\{\th | q(\theta) \le z\}.
\end{array}
\end{equation}
Теперь мы можем записать балансовое ограничение контролирующего органа так:
\begin{equation}
\label{feasib1}
\int\limits_0^1 \lambda_q (z) dF_q(z) \le A.
\end{equation}

Суммируем временную структуру изучаемой игры. В первый момент контролирующий
орган объявляет определённый контракт $\lambda$, который предписывает 
интенсивности $\lambda_q (z)$ проверок каждому значению переменной $z$, при 
условии, что реализовался (и стал наблюдаемым) профиль $q$. Затем подчинённые 
играют на втором этапе одновременную игру, выбирая свои действия $z$ (будучи 
информированными относительно выбранной контролирующим органом стратегии 
$\lambda$, и что более важно, веря в её состоятельность). После того, как их 
действия осуществлены, и профиль $q$ наблюдён контролирующим органом, 
распределение $\lambda_q(\cdot)$ уже имплементируется автоматически, и 
подчинённые получают свои выигрыши, равные
\begin{equation}
\label{payoff}
u(\theta) = u(\th,z,q) =
z \cdot [b(\theta) - D \cdot \lambda_q(z)].
\end{equation}

Введем в рассмотрение целевой функционал $X(q)$ контролирующего органа. Как 
правило, можно ограничиться рассмотрением {\em линейных целевых функционалов} 
вида
\begin{equation}
\label{goals}
X(q) =\int\limits_0^1 x(\theta) q(\theta) d\theta.
\end{equation}
Частный случай функционала~(\ref{goals}) состоит в минимизации среднего 
уровня коррупции; он соответствует случаю $x(\theta) \equiv 1$.

Линейный функционал~(\ref{goals}) общего вида можно проинтерпретировать в 
рамках сценария с налогоукрытием следующим образом: это~--- минимизация вреда 
от коррупции. Тогда $x(\theta)$~--- коэффициенты вредоносности коррупционных 
сделок, осуществляемых в соответствующих секторах. Естественно предположить, 
что $x(\th) \equiv x_i$ одинаков для всех $\th$ с $b(\th) = b_i$; если, 
вдобавок, все подчинённые одного типа $i$ выберут одинаковую степень 
$z = z_i$ (что будет верно в равновесии, см. ниже), то 
функционал~(\ref{goals}) перепишется в виде
\begin{equation}
\label{goal}
X(q) = \sum_i x_i z_i \mu_i.
\end{equation}

Теперь мы можем описать задачу контролирующего органа:
\begin{equation}
\label{prinpro}
\begin{array}{c}
X(q) \to \max\limits_{\lambda}, \quad s.t.
\\
q \,\, \mbox{ является равновесием в игре второго этапа, }
\\
\mbox{ соответствующей стратегии } \lambda.
\end{array}
\end{equation}
Под равновесием здесь имеется в виду концепция решения, упомянутая выше:
итеративно достигаемое сильное равновесие Нэша (точное определение см. в
следующем разделе).

Альтернативная постановка задачи контролирующего органа состоит в том, что 
общее число ресурсов (или проверок) $A$ является также переменной выбора, 
наряду с контрактом $\lambda$. Тем не менее, даже в этом случае 
предполагается, что $A$, также как и $\lambda$, объявляется в самом начале 
игры, в момент $0$, и в дальнейшем варьированию не подлежит. Обозначим за
$m$ цену ресурса, в единицах полезности контролирующего органа. Тогда 
максимизационная задача принимает вид
\begin{equation}
\label{prinprob}
\begin{array}{c}
X(q)-mA \to \max\limits_{(A,\lambda)}, \quad s.t.
\\
q \,\, \mbox{ является равновесием в игре второго этапа, }
\\
\mbox{ соответствующей стратегии } (A,\lambda).
\end{array}
\end{equation}

Можно и вовсе не специфицировать целевой функционал, вместо этого занимаясь
описанием Парето-оптимальных стратегий, в соответствии с частичным порядком,
заданным на множестве $[0,1]^{[0,1]}$ всех профилей $q$ (подразумевая, что
данное упорядочение уважается предпочтениями контролирующего органа). Ниже
дано строгое определение понятия Парето оптимальной стратегии.

{\bf Определение.} Стратегия $\lambda$ называется Парето оптимальной, если
профиль коррупционных выборов агентов в равновесии, соответствующем 
$\lambda$, не может быть (нестрого) уменьшен покомпонентно за счёт выбора
другой стратегии $\lambda'$, требующей не большего, чем $\lambda$ объёма
ресурсов для своей имплементации.

Иными словами, стратегия является Парето оптимальной, если нельзя, исходя
из того же объёма ресурсов, понизить коррупционные выборы одних агентов без
завышения выборов других.

Следующий раздел вводит в рассмотрение класс стратегий, упоминавшийся выше.
Для этого класса всегда существует и единственно итеративно достигаемое 
сильное Нэш-равновесие.

\section{Допустимые стратегии и пороговые\\
стратегии}

Теперь мы уделим пристальное внимание различным допустимым стратегиям.
Множество всех допустимых стратегий является невообразимо богатым: 
это~--- множество всех функционалов, аргументом которых является
пара $(q,z)$, состоящая из наблюдаемого профиля $q$, вместе с данным значением
переменной выбора (или действия), $z$. Ниже представлено несколько примеров 
допустимых (и недопустимых) стратегий.

Балансовое ограничение~(\ref{feasib1}), выражающее условие допустимости 
стратегии, является достаточно сильным, чтобы исключить из рассмотрения на 
первый взгляд разумные и легко трактуемые стратегии. Например, представим 
себе такую гипотетически возможную стратегию контролирующего органа: 
{\em все, кто выберут $z > \bar z$, будут подвергнуты проверке с 
интенсивностью $\bar A$}. Такая стратегия допустимой является лишь в том 
случае, если в распоряжении контролирующего органа находится {\em огромное} 
количество ресурсов, достаточное для проверки всех подчинённых с указанной 
интенсивностью, потому что возможна ситуация, когда вообще все перейдут эту 
черту~--- такой профиль априори может реализоваться. Если же общий объём 
средств не столь велик, то подчинённые, будучи рациональными и наблюдая этот 
объём (согласно предположению модели), воспримут данную угрозук как 
невыполнимую, и скорее всего все и впрямь перейдут эту черту.

Таким образом, столь привлекательный план, как обещать проверку данной
степени интенсивности всем тем, кто переступит определённую черту, не
является выполнимой стратегией, потому что её имплементация, как правило, 
не может быть гарантирована а постериори.

Примером допустимой стратегии является, например, обещание потратить {\em все
ресурсы, какие есть}, поровну между подчинёнными, перешедшими черту $\bar z$.
Тогда они тоже будут \лк обслужены\пк\ с равной интенсивностью, но точное
значение этой интенсивности сложится в процессе игры второго уровня. В отличие 
от вышеописанного, данное обещание выполнимо по определению, ибо мы обещаем
распределять один и тот же запас средств. 

{\bf Стратегия постоянная.} Согласно ей, знание профиля $q$ вообще 
игнорируется, и все подчинённые проверяются с одинаковой интенсивностью.

{\bf Пороговая стратегия отсечения.} Выбирается определённый уровень
$\bar z$, и все ресурсы тратятся поровну на тех, чей выбор $z$ строго выше
$\bar z$.\footnote{Строгого неравенства нужно требовать для того, чтобы
равновесие существовало: иначе часть подчинённых захочет выбрать степень
вовлечённости, бесконечно близкую к $\bar z$ снизу.} Тогда, конечно, никто
не выберет степень меньшую, чем $\bar z$, но частота проверок тех, кто
\лк зашкалит\пк\ за $\bar z$, зависит от того, как много их окажется всего.
Если все выберут высокую степень нарушения, то результат будет такой же, как
и в предыдущем примере~--- всех проверят с одинаковой интенсивностью. В
случае же, когда все остальные выбрали степень, равную $\bar z$, данному
подчинённому ничего не остаётся, как сделать то же самое: в противном случае 
на него падёт \лк весь огонь батарей\пк\ контролирующего органа.

{\bf Стратегия промежуточного типа.} Часть ресурсов тратится на поголовную
проверку, оставшаяся часть идёт на дополнительную проверку тех, чей выбор $z$
зашкалил за определённое $\bar z$. Таких стратегий имеется уже целое двумерное
семейство, включающее оба вышеописанных типа. Семейство определяется
параметрами $(A_1, \bar z)$, где $A_1$~--- количество дополнительных
проверок, а $A-A_1$~--- поголовных. 

Следующая ступень обобщения приводит нас к отмеченному классу допустимых 
стратегий, который будет подвергнут изучению в последующих разделах работы.
Стратегии этого класса всегда имплементируют в игре второго уровня 
единственное сильное равновесие Нэша, к которому можно прийти итеративно.

{\bf Многоступенчатая пороговая стратегия} состоит в том, чтобы фиксировать 
несколько уровней отсечения (порогов) $z_i$, и для каждого из них назначить 
$A_i$ проверок, дополнительно поровну распределяемых между теми, кто зашкалил 
за соответствующий уровень $z_i$. При этом должно быть $A= \sum_i A_i$. Все 
вышеприведённые примеры стратегий укладываются в данную схему. Балансовое
ограничение~(\ref{feasib1}) для таких стратегий выполнено автоматически.
Каждая такая стратегия может быть охарактеризована определённой 
{\em кумулятивной функцией распределения ресурсов}
$\ad$, где
\begin{equation}
\label{stra23}
A(z) = \sum_{i: z_i < z} A_i,
\end{equation}
или набором
\begin{equation}
\label{strate}
(A_1, z_1; \dots; A_k, z_k).
\end{equation}
Обратим внимание на то, что $\ad$~--- это {\em не} кумулятивное
распределение интенсивностей проверок соответствующего контракта $\lambda$. 
Чтобы получить $\lambda=\lambda_{\ad}$, будем рассуждать так. Пусть 
контролирующий орган объявил стратегию $\ad$, заданную 
набором~(\ref{strate}). Если реализованный (и затем наблюдённый) 
профиль есть $q$ (вместе с соответствующей функцией
распределения $F_q(\cdot)$ подчинённых по их выборам, $z$), то $\forall i$ 
имеем, что $1-F(z_i)$ подчинённых выбрали $z>z_i$, и дополнительный объём
$A_i$ ресурсов должен быть распределён между ними. Тогда интенсивность
проверок подчинённого, выбравшего $z$, окажется равной
\begin{equation}
\label{intens3}
\lambda_{\ad}(z,q) = \sum_{\{i: z_i < z\}} \frac{A_i}{1-F(z_i)}.
\end{equation}
Эта формула полностью характеризует игру между подчинёнными, возникающую на
втором этапе, при условии выбора контролирующим органом многоступенчатой 
пороговой стратегии $\ad$.

Существует ещё один класс стратегий контролирующего органа. Эти стратегии 
являются наилучшими в тех случаях, когда кооперативные возможности игроков 
слабы (то есть тогда, когда равновесие Нэша является разумной концепцией 
решения игры второго этапа). А именно, они реализуют бескоррупционное 
равновесие. Мы остановимся на описании этого класса стратегий чуть более 
подробно, для того, чтобы сопоставить их со стратегиями порогового типа.

{\em Стратегии квантильного типа.} Также как и в предыдущем примере,
фиксируется несколько уровней отсечения $p_1 > p_2 > \dots > p_l$, которые
теперь интерпретируются как процентные квантили сверху. Каждой из квантилей 
назначаются дополнительные $A_i$ проверок, но теперь дополнительным проверкам 
подвергаются те подчинённые, которые вошли в соответствующие квантили, 
построенные по реализовавшемуся профилю $q$. Например, стратегия квантильного 
типа $(10\%, A_1; \, 40\%, A-A_1)$ предписывает распределить $A_1$ проверок 
поровну между 10-ю процентами наиболее коррумпированных подчинённых, и 
распределить остальные проверки поровну между 40\% наиболее коррумпированных 
(включая и тех, между которыми уже распределено $A_1$ проверок). Если 
же окажется, например, что первые 20\% подчинённых выбрали одинаковое $z$, 
то по определению такая стратегия распределяет $A_1$ проверок между ними 
всеми. 

Существуют стратегии квантильного типа, которые имплементируют в игре 
второго этапа единственное равновесие Нэша, состоящее в нулевом уровне 
коррупции: $z \equiv 0$ (например, таковой будет, как легко понять, 
стратегия проверить в максимальной степени одного наиболее 
коррумпированного агента). Тем не менее, их вряд ли можно рекомендовать 
на практике налоговой инспекции, потому что это единственное равновесие 
не является коалиционно устойчивым, иными словами, оно неустойчиво 
относительно скоординированного поведения агентов. Поэтому в реальности 
такие стратегии не имплементируют бескоррупционного равновесия, вместо 
этого порождая неконтролируемое поведение агентов на второй ступени игры, 
с последовательным непредсказуемым образованием и развалом коалиций 
(благодаря силам, форсирующим кооперацию различного рода). Мы ограничимся
исследованием стратегий порогового типа, которые лишь условно оптимальны, 
но легко имплементируемы.

Следующий раздел содержит основные результаты анализа игры, описанной выше.
Доказательства теорем содержатся в Приложениях 3 и 4. Приложение 5 суммирует
все обозначения, относящиеся к модели.